# -*- coding: utf-8 -*-
"""gender_classifier.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IX5omTo3al8bnjXrqIlZyWwPbj8_NLpr
"""

import pickle
import os
import librosa
import numpy as np
from keras.models import model_from_json
from sklearn.preprocessing import StandardScaler

# Owner : Eyad Alswaity 
# Version 1.0
# This class is used to predict speakers gender by calling its function predict_gender(files_path) 
# by passing files path of the audio file that contains utterance.

# in class initialization just pass the directory where model json and h5 are loaded.


class Speakers_Gender_Classifier():

  def __init__(self,root_dir):
    json_file = open(os.path.join(root_dir,'mfcc_model_2.json'), 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights(os.path.join(root_dir, 'mfcc_model_2.h5'))
    self.model = loaded_model

    self.number_of_mfcc = 40
    self.frames = 87
    self.genders = ['M','F']
    self.duration = 2 #seconds
  
  def get_mfcc_properties(self,signal_data,sr):
    signal = signal_data
    # pad signals of max seconds duration
    signal_length = self.duration * sr
    length = signal.shape[0]
    pad_length = signal_length - length
    if pad_length > 0:
      padding = np.zeros(pad_length)
      signal = np.hstack((signal, padding))
    mfcc_feats = librosa.feature.mfcc(signal, sr, n_mfcc=self.number_of_mfcc)

    return mfcc_feats

  def predict_gender(self,audio_file_path):
    sound_data, sr = librosa.load(audio_file_path,duration=duration)
    sc = StandardScaler()
    mfcc_data = sc.fit_transform(self.get_mfcc_properties(sound_data,sr))    
    pred = self.model.predict(np.reshape(mfcc_data,[1,self.number_of_mfcc,self.frames,1]))

    return genders[int(round(pred.reshape(-1)[0]))]